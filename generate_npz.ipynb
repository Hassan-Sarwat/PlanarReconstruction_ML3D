{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as iio\n",
    "import math\n",
    "import os, sys, argparse\n",
    "import inspect\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorPalette:\n",
    "    def __init__(self, numColors):\n",
    "        np.random.seed(2)\n",
    "        #self.colorMap = np.random.randint(255, size = (numColors, 3))\n",
    "        #self.colorMap[0] = 0\n",
    "\n",
    "\n",
    "        self.colorMap = np.array([[255, 0, 0],\n",
    "                                  [0, 255, 0],\n",
    "                                  [0, 0, 255],\n",
    "                                  [80, 128, 255],\n",
    "                                  [255, 230, 180],\n",
    "                                  [255, 0, 255],\n",
    "                                  [0, 255, 255],\n",
    "                                  [100, 0, 0],\n",
    "                                  [0, 100, 0],\n",
    "                                  [255, 255, 0],\n",
    "                                  [50, 150, 0],\n",
    "                                  [200, 255, 255],\n",
    "                                  [255, 200, 255],\n",
    "                                  [128, 128, 80],\n",
    "                                  [0, 50, 128],\n",
    "                                  [0, 100, 100],\n",
    "                                  [0, 255, 128],\n",
    "                                  [0, 128, 255],\n",
    "                                  [255, 0, 128],\n",
    "                                  [128, 0, 255],\n",
    "                                  [255, 128, 0],\n",
    "                                  [128, 255, 0],\n",
    "        ])\n",
    "\n",
    "        if numColors > self.colorMap.shape[0]:\n",
    "            self.colorMap = np.concatenate([self.colorMap, np.random.randint(255, size = (numColors - self.colorMap.shape[0], 3))], axis=0)\n",
    "            pass\n",
    "\n",
    "        return\n",
    "\n",
    "    def getColorMap(self):\n",
    "        return self.colorMap\n",
    "\n",
    "    def getColor(self, index):\n",
    "        if index >= colorMap.shape[0]:\n",
    "            return np.random.randint(255, size = (3))\n",
    "        else:\n",
    "            return self.colorMap[index]\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawDepthImage(depth):\n",
    "    #return cv2.applyColorMap(np.clip(depth / 10 * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    return 255 - np.clip(depth / 5 * 255, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawSegmentationImage(segmentations, randomColor=None, numColors=22, blackIndex=-1):\n",
    "    if segmentations.ndim == 2:\n",
    "        numColors = max(numColors, segmentations.max() + 2, blackIndex + 1)\n",
    "    else:\n",
    "        numColors = max(numColors, segmentations.shape[2] + 2, blackIndex + 1)\n",
    "        pass\n",
    "    randomColor = ColorPalette(numColors).getColorMap()\n",
    "    if blackIndex >= 0:\n",
    "        randomColor[blackIndex] = 0\n",
    "        pass\n",
    "    width = segmentations.shape[1]\n",
    "    height = segmentations.shape[0]\n",
    "    if segmentations.ndim == 3:\n",
    "        #segmentation = (np.argmax(segmentations, 2) + 1) * (np.max(segmentations, 2) > 0.5)\n",
    "        segmentation = np.argmax(segmentations, 2)\n",
    "    else:\n",
    "        segmentation = segmentations\n",
    "        pass\n",
    "    segmentation = segmentation.astype(int)\n",
    "    return randomColor[segmentation.reshape(-1)].reshape((height, width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_min_rows(plane):\n",
    "    current_rows = plane.shape[0]\n",
    "    \n",
    "    if current_rows < 20:\n",
    "        # Add full 0 rows until it has 20 rows\n",
    "        additional_rows = 20 - current_rows\n",
    "        zero_rows = np.zeros((additional_rows, plane.shape[1]))\n",
    "        plane = np.vstack([plane, zero_rows])\n",
    "    elif current_rows > 20:\n",
    "        # Take the first 20 rows if it has more than 20 rows\n",
    "        plane = plane[:20, :]\n",
    "    \n",
    "    return plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://github.com/art-programmer/PlaneNet/blob/ccc4423d278388d01cb3300be992b951b90acc7a/pytorch/datasets/scannet_scene.py\n",
    "## This class handle one scene of the scannet dataset and provide interface for dataloaders\n",
    "class ScanNetScene():\n",
    "    def __init__(self, scenePath, scene_id):\n",
    "        \n",
    "    \n",
    "        self.metadata = np.zeros(10)\n",
    "\n",
    "        with open(scenePath + '/' + scene_id + '.txt') as f:\n",
    "                    for line in f:\n",
    "                        line = line.strip()\n",
    "                        tokens = [token for token in line.split(' ') if token.strip() != '']\n",
    "                        if tokens[0] == \"fx_color\":\n",
    "                            self.metadata[0] = float(tokens[2])\n",
    "                        if tokens[0] == \"fy_color\":\n",
    "                            self.metadata[1] = float(tokens[2])\n",
    "                        if tokens[0] == \"mx_color\":\n",
    "                            self.metadata[2] = float(tokens[2])                            \n",
    "                        if tokens[0] == \"my_color\":\n",
    "                            self.metadata[3] = float(tokens[2])                            \n",
    "                        elif tokens[0] == \"colorWidth\":\n",
    "                            self.colorWidth = int(tokens[2])\n",
    "                        elif tokens[0] == \"colorHeight\":\n",
    "                            self.colorHeight = int(tokens[2])\n",
    "                        elif tokens[0] == \"depthWidth\":\n",
    "                            self.depthWidth = int(tokens[2])\n",
    "                        elif tokens[0] == \"depthHeight\":\n",
    "                            self.depthHeight = int(tokens[2])\n",
    "                        elif tokens[0] == \"numDepthFrames\":\n",
    "                            self.numImages = int(tokens[2])\n",
    "                            pass\n",
    "                        continue\n",
    "                    pass\n",
    "        self.depthShift = 1000.0\n",
    "        self.imagePaths = glob.glob(scenePath + '/frames/color/*.jpg')                \n",
    "        pass\n",
    "                    \n",
    "        self.metadata[4] = self.colorWidth\n",
    "        self.metadata[5] = self.colorHeight\n",
    "        self.planes = np.load(scenePath + '/annotation/planes.npy')\n",
    "\n",
    "\n",
    "        return\n",
    "\n",
    "    def getItemCached(self, imageIndex):\n",
    "        segmentationPath = self.imagePaths[imageIndex]\n",
    "        imagePath = segmentationPath.replace('annotation_new/', 'frames/').replace('segmentation.png', 'color.jpg')\n",
    "        image = cv2.imread(imagePath)\n",
    "        depth = cv2.imread(imagePath.replace('color.jpg', 'depth.pgm'), -1).astype(np.float32) / self.metadata[6]\n",
    "        extrinsics_inv = []\n",
    "        with open(imagePath.replace('color.jpg', 'pose.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                extrinsics_inv += [float(value) for value in line.strip().split(' ') if value.strip() != '']\n",
    "                continue\n",
    "            pass\n",
    "        extrinsics_inv = np.array(extrinsics_inv).reshape((4, 4))\n",
    "        extrinsics = np.linalg.inv(extrinsics_inv)\n",
    "        temp = extrinsics[1].copy()\n",
    "        extrinsics[1] = extrinsics[2]\n",
    "        extrinsics[2] = -temp\n",
    "\n",
    "        segmentation = cv2.imread(segmentationPath, -1).astype(np.int32)\n",
    "        planes = np.load(segmentationPath.replace('segmentation.png', 'planes.npy'))\n",
    "\n",
    "        info = [image, planes, segmentation, depth, self.metadata]\n",
    "\n",
    "        if False:\n",
    "            print(planes)\n",
    "            print(depth.min(), depth.max())\n",
    "            cv2.imwrite('test/image.png', image)\n",
    "            cv2.imwrite('test/depth_ori.png', drawDepthImage(depth))\n",
    "            cv2.imwrite('test/segmentation.png', drawSegmentationImage(segmentation))\n",
    "            exit(1)\n",
    "\n",
    "        return info\n",
    "\n",
    "    def transformPlanes(self, transformation, planes):\n",
    "        planeOffsets = np.linalg.norm(planes, axis=-1, keepdims=True)\n",
    "        \n",
    "        centers = planes\n",
    "        centers = np.concatenate([centers, np.ones((planes.shape[0], 1))], axis=-1)\n",
    "        newCenters = np.transpose(np.matmul(transformation, np.transpose(centers)))\n",
    "        newCenters = newCenters[:, :3] / newCenters[:, 3:4]\n",
    "\n",
    "        refPoints = planes - planes / np.maximum(planeOffsets, 1e-4)\n",
    "        refPoints = np.concatenate([refPoints, np.ones((planes.shape[0], 1))], axis=-1)\n",
    "        newRefPoints = np.transpose(np.matmul(transformation, np.transpose(refPoints)))\n",
    "        newRefPoints = newRefPoints[:, :3] / newRefPoints[:, 3:4]\n",
    "\n",
    "        planeNormals = newRefPoints - newCenters\n",
    "        planeNormals /= np.linalg.norm(planeNormals, axis=-1, keepdims=True)\n",
    "        planeOffsets = np.sum(newCenters * planeNormals, axis=-1, keepdims=True)\n",
    "        newPlanes = planeNormals * planeOffsets\n",
    "        return newPlanes\n",
    "        \n",
    "    def __getitem__(self, imageIndex):\n",
    "        \n",
    "        imagePath = self.imagePaths[imageIndex]\n",
    "\n",
    "       \n",
    "        segmentationPath = imagePath.replace('frames/color/', 'annotation/segmentation/').replace('.jpg', '.png')\n",
    "        depthPath = imagePath.replace('color', 'depth').replace('.jpg', '.png')\n",
    "        posePath = imagePath.replace('color', 'pose').replace('.jpg', '.txt')\n",
    "        pass\n",
    "        \n",
    "        image = cv2.imread(imagePath)\n",
    "        depth = cv2.imread(depthPath, -1).astype(np.float32) / self.depthShift\n",
    "\n",
    "        extrinsics_inv = []\n",
    "        with open(posePath, 'r') as f:\n",
    "            for line in f:\n",
    "                extrinsics_inv += [float(value) for value in line.strip().split(' ') if value.strip() != '']\n",
    "                continue\n",
    "            pass\n",
    "        extrinsics_inv = np.array(extrinsics_inv).reshape((4, 4))\n",
    "        extrinsics = np.linalg.inv(extrinsics_inv)\n",
    "        \n",
    "        segmentation = cv2.imread(segmentationPath, -1).astype(np.int32)\n",
    "        segmentation = segmentation[:, :, 2] * 256 * 256 + segmentation[:, :, 1] * 256 + segmentation[:, :, 0]\n",
    "        \n",
    "        segmentation = segmentation / 100 - 1\n",
    "        segments, counts = np.unique(segmentation, return_counts=True)\n",
    "        segmentList = zip(segments.tolist(), counts.tolist())\n",
    "        segmentList = [segment for segment in segmentList if (int(segment[0]) not in [-1, 167771]) and  (int(segment[0])< self.planes.shape[0])]  #added the constriction that the index is inside the range of planes\n",
    "        segmentList = sorted(segmentList, key=lambda x:-x[1])\n",
    "        \n",
    "        newPlanes = []\n",
    "        newSegmentation = np.full(segmentation.shape, fill_value=-1, dtype=np.int32)\n",
    "        for newIndex, (oriIndex, count) in enumerate(segmentList):\n",
    "            if count < (segmentation.shape[0] * segmentation.shape[1]) * 0.02:\n",
    "                continue\n",
    "            newPlanes.append(self.planes[int(oriIndex)])\n",
    "            newSegmentation[segmentation == int(oriIndex)] = newIndex\n",
    "            continue\n",
    "\n",
    "        newPlanes = np.array(newPlanes)\n",
    "\n",
    "        temp = extrinsics[1].copy()\n",
    "        extrinsics[1] = extrinsics[2]\n",
    "        extrinsics[2] = -temp\n",
    "\n",
    "        if len(newPlanes) > 0:\n",
    "            newPlanes = self.transformPlanes(extrinsics, newPlanes)\n",
    "            pass\n",
    "\n",
    "        image = cv2.resize(image, (256, 192))\n",
    "        depth = cv2.resize(depth, (256, 192))\n",
    "        newSegmentation= cv2.resize(newSegmentation, (256, 192), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "\n",
    "        info = [image, newPlanes, newSegmentation, depth, self.metadata]\n",
    "\n",
    "        if False:\n",
    "            print(newPlanes)\n",
    "            print(np.unique(newSegmentation))\n",
    "            print(depth.min(), depth.max())\n",
    "            cv2.imwrite('/home/steve/Documents/ml3d/Project/NPZ/test/image.png', image)\n",
    "            cv2.imwrite('/home/steve/Documents/ml3d/Project/NPZ/test/depth_ori.png', drawDepthImage(depth))\n",
    "            cv2.imwrite('/home/steve/Documents/ml3d/Project/NPZ/test/segmentation.png', drawSegmentationImage(newSegmentation))\n",
    "            for index in range(newSegmentation.max() + 1):\n",
    "                print(index, newPlanes[index])\n",
    "                cv2.imwrite('/home/steve/Documents/ml3d/Project/NPZ/test/mask_' + str(index) + '.png', (newSegmentation == index).astype(np.uint8) * 255)\n",
    "                continue\n",
    "            exit(1)\n",
    "        \n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m num_files1 \u001b[38;5;241m==\u001b[39m num_files2\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_files1):\n\u001b[0;32m---> 19\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     21\u001b[0m     plane \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[16], line 121\u001b[0m, in \u001b[0;36mScanNetScene.__getitem__\u001b[0;34m(self, imageIndex)\u001b[0m\n\u001b[1;32m    118\u001b[0m segmentation \u001b[38;5;241m=\u001b[39m segmentation[:, :, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m+\u001b[39m segmentation[:, :, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m+\u001b[39m segmentation[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    120\u001b[0m segmentation \u001b[38;5;241m=\u001b[39m segmentation \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 121\u001b[0m segments, counts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m segmentList \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(segments\u001b[38;5;241m.\u001b[39mtolist(), counts\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    123\u001b[0m segmentList \u001b[38;5;241m=\u001b[39m [segment \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m segmentList \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mint\u001b[39m(segment[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m167771\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m  (\u001b[38;5;28mint\u001b[39m(segment[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplanes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scenes =  ['0000_00', '0111_01' ,'0234_00' ,'0368_00' ,'0515_02', '0005_00' ,'0033_00', '0068_00', '0152_01', '0177_00', '0289_00', '0341_00', '0476_00', '0610_01', '0679_00']         #['0000_00', '0111_01' ,'0234_00' ,'0368_00' ,'0515_02']\n",
    "for num_s, s in enumerate(scenes):\n",
    "    scene_id = s\n",
    "    sn = ScanNetScene('/home/steve/Documents/ml3d/Project/Data/scans/scene' + scene_id, 'scene'+scene_id)\n",
    "    path_scenes = '/home/steve/Documents/ml3d/Project/Data/scans'\n",
    "    path_image = path_scenes + '/scene' + scene_id + '/frames/color'\n",
    "    path_depth = path_scenes + '/scene' + scene_id + '/frames/depth'\n",
    "    path_segmentation = path_scenes + '/scene' + scene_id + '/annotation/segmentation'\n",
    "    path_plane = path_scenes + '/scene' + scene_id + '/annotation/planes.npy'\n",
    "    path_semantics = path_scenes + '/scene' + scene_id + '/scene' + scene_id  + '_2d-label/label'\n",
    "    path_pose = path_scenes + '/scene' + scene_id + '/frames/pose'\n",
    "    path_intrinsic= path_scenes+ '/scene' + scene_id + '/frames/intrinsic/intrinsic_depth.txt'\n",
    "    files1 = os.listdir(path_image)\n",
    "    num_files1 = len(files1)\n",
    "    files2 = os.listdir(path_depth)\n",
    "    num_files2 = len(files2)\n",
    "    assert num_files1 == num_files2\n",
    "    for i in range(0, num_files1):\n",
    "        data = sn.__getitem__(i)\n",
    "        image = np.array(data[0])\n",
    "        plane = np.array(data[1])\n",
    "        if plane.shape[0] == 0:\n",
    "            continue\n",
    "        num_planes = np.array(plane.shape[0])\n",
    "        plane = ensure_min_rows(plane)\n",
    "        segmentation = data[2]\n",
    "        segmentation = segmentation.reshape(*segmentation.shape, 1)\n",
    "        depth = data[3]\n",
    "        depth = depth.reshape(*depth.shape, 1)\n",
    "        segmentation_path = path_segmentation + '/' + str(i) + '.png'\n",
    "        semantic_path = path_semantics + '/' + str(i) + '.png'\n",
    "        semantic = np.array(cv2.resize(iio.v3.imread(semantic_path),(256, 192), interpolation=cv2.INTER_NEAREST))\n",
    "        np.savez('/home/steve/Documents/ml3d/npz_okay/' + str(num_s*2000000 + i) + '.npz', image = image, plane = plane, depth = depth, semantics = semantic, segmentation= segmentation, num_planes = num_planes.reshape((1,)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train and val directories and txt\n",
    "\n",
    "source_directory=\"/home/steve/Documents/ml3d/npz_okay/\"\n",
    "train_txt=\"/home/steve/Documents/ml3d/Project/NPZ/train.txt\"\n",
    "val_txt=\"/home/steve/Documents/ml3d/Project/NPZ/val.txt\"\n",
    "\n",
    "train_destination=\"/home/steve/Documents/ml3d/Project/PlanarReconstruction_ML3D/processed_data/train\"\n",
    "val_destination=\"/home/steve/Documents/ml3d/Project/PlanarReconstruction_ML3D/processed_data/val\"\n",
    "\n",
    "# Create the destination directories\n",
    "os.makedirs(train_destination, exist_ok=True)\n",
    "os.makedirs(val_destination, exist_ok=True)\n",
    "\n",
    "# Copy files listed in train.txt to train directory\n",
    "with open(train_txt, 'r') as file:\n",
    "    for filename in file.read().splitlines():\n",
    "        shutil.copy(os.path.join(source_directory, filename), train_destination)\n",
    "\n",
    "# Copy files listed in val.txt to val directory\n",
    "with open(val_txt, 'r') as file:\n",
    "    for filename in file.read().splitlines():\n",
    "        shutil.copy(os.path.join(source_directory, filename), val_destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
